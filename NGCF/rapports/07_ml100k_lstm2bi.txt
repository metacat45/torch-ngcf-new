hephaestos@toto:/media/stock/projets/20220130_CNAM_graphs/NGCF-PyTorch-new/NGCF$ python3 main_lstm2.py --dataset ml-100k --regs [1e-5] --embed_size 64 --layer_size [64,64,64] --lr 0.0001 --save_flag 1 --pretrain 0 --batch_size 1024 --epoch 100 --verbose 1 --node_dropout [0.1] --mess_dropout [0.1,0.1,0.1] --weights_path "models/ml100k/07_lstm2/" 
n_users=943, n_items=1682
n_interactions=100000
n_train=90404, n_test=9596, sparsity=0.06305
already load adj matrix (2625, 2625) 0.01631903648376465
Epoch 0 [38.4s]: train==[47.54893=47.51830 + 0.03064]
Epoch 1 [38.7s]: train==[34.65093=34.62357 + 0.02736]
Epoch 2 [38.4s]: train==[33.80302=33.77535 + 0.02768]
Epoch 3 [38.2s]: train==[32.75296=32.72063 + 0.03233]
Epoch 4 [38.2s]: train==[30.75353=30.71670 + 0.03683]
Epoch 5 [38.3s]: train==[28.52100=28.48414 + 0.03685]
Epoch 6 [38.6s]: train==[27.72883=27.69798 + 0.03085]
Epoch 7 [38.4s]: train==[27.27539=27.25306 + 0.02233]
Epoch 8 [38.4s]: train==[26.74957=26.73336 + 0.01621]
Epoch 9 [38.4s + 0.5s]: train==[26.50679=26.49519 + 0.01161], recall=[0.17928, 0.45843], precision=[0.06501, 0.03933], hit=[0.67975, 0.92365], ndcg=[0.13701, 0.22835]
save the weights in path:  models/ml100k/07_lstm2/9.pkl
Epoch 10 [38.4s]: train==[26.32564=26.31545 + 0.01018]
Epoch 11 [38.4s]: train==[26.02359=26.01316 + 0.01043]
Epoch 12 [38.4s]: train==[26.09309=26.08285 + 0.01024]
Epoch 13 [38.5s]: train==[25.89811=25.88747 + 0.01064]
Epoch 14 [38.4s]: train==[25.79246=25.78145 + 0.01100]
Epoch 15 [38.4s]: train==[25.76737=25.75680 + 0.01058]
Epoch 16 [38.4s]: train==[25.61457=25.60361 + 0.01097]
Epoch 17 [38.4s]: train==[25.73257=25.72139 + 0.01118]
Epoch 18 [38.4s]: train==[25.26556=25.25299 + 0.01256]
Epoch 19 [38.5s + 0.5s]: train==[24.47245=24.45766 + 0.01479], recall=[0.20547, 0.49376], precision=[0.08112, 0.04279], hit=[0.71580, 0.93637], ndcg=[0.17004, 0.26032]
save the weights in path:  models/ml100k/07_lstm2/19.pkl
Epoch 20 [38.4s]: train==[23.81619=23.79987 + 0.01631]
Epoch 21 [38.7s]: train==[23.27819=23.26083 + 0.01736]
Epoch 22 [39.5s]: train==[22.40396=22.38338 + 0.02058]
Epoch 23 [38.7s]: train==[22.02871=22.00674 + 0.02196]
Epoch 24 [38.7s]: train==[21.43917=21.41660 + 0.02257]
Epoch 25 [38.8s]: train==[20.84070=20.81661 + 0.02409]
Epoch 26 [39.2s]: train==[20.65964=20.63655 + 0.02308]
Epoch 27 [39.1s]: train==[20.29819=20.27544 + 0.02275]
Epoch 28 [39.1s]: train==[20.16232=20.14042 + 0.02190]
Epoch 29 [38.7s + 0.6s]: train==[19.81116=19.78981 + 0.02134], recall=[0.25604, 0.57310], precision=[0.10483, 0.05077], hit=[0.77200, 0.95970], ndcg=[0.21330, 0.31387]
save the weights in path:  models/ml100k/07_lstm2/29.pkl
Epoch 30 [38.9s]: train==[20.03907=20.01929 + 0.01977]
Epoch 31 [38.5s]: train==[20.06279=20.04307 + 0.01971]
Epoch 32 [38.5s]: train==[19.98338=19.96478 + 0.01860]
Epoch 33 [38.6s]: train==[19.64727=19.62960 + 0.01767]
Epoch 34 [38.6s]: train==[19.51148=19.49467 + 0.01682]
Epoch 35 [38.6s]: train==[19.66605=19.65055 + 0.01549]
Epoch 36 [38.7s]: train==[19.20416=19.18929 + 0.01488]
Epoch 37 [38.5s]: train==[19.75435=19.74018 + 0.01417]
Epoch 38 [38.5s]: train==[19.30290=19.28898 + 0.01392]
Epoch 39 [38.5s + 0.5s]: train==[19.02974=19.01638 + 0.01335], recall=[0.26439, 0.59221], precision=[0.10562, 0.05198], hit=[0.79427, 0.96501], ndcg=[0.21663, 0.32060]
save the weights in path:  models/ml100k/07_lstm2/39.pkl
Epoch 40 [38.5s]: train==[18.90682=18.89391 + 0.01291]
Epoch 41 [38.4s]: train==[19.01420=19.00164 + 0.01256]
Epoch 42 [38.4s]: train==[18.75381=18.74139 + 0.01242]
Epoch 43 [38.4s]: train==[18.72165=18.70986 + 0.01179]
Epoch 44 [38.4s]: train==[18.86694=18.85567 + 0.01127]
Epoch 45 [38.3s]: train==[18.41046=18.39905 + 0.01141]
Epoch 46 [38.3s]: train==[19.11849=19.10757 + 0.01092]
Epoch 47 [38.4s]: train==[18.73315=18.72240 + 0.01075]
Epoch 48 [38.3s]: train==[18.75757=18.74697 + 0.01060]
Epoch 49 [38.4s + 0.5s]: train==[18.65834=18.64799 + 0.01035], recall=[0.26255, 0.59020], precision=[0.10610, 0.05195], hit=[0.78473, 0.96607], ndcg=[0.21358, 0.31799]
Epoch 50 [38.5s]: train==[18.49373=18.48311 + 0.01062]
Epoch 51 [38.5s]: train==[18.52746=18.51707 + 0.01039]
Epoch 52 [38.5s]: train==[18.47309=18.46279 + 0.01030]
Epoch 53 [38.5s]: train==[18.36266=18.35240 + 0.01025]
Epoch 54 [38.5s]: train==[18.76005=18.74994 + 0.01010]
Epoch 55 [38.5s]: train==[18.35046=18.34023 + 0.01023]
Epoch 56 [38.4s]: train==[18.31042=18.30021 + 0.01020]
Epoch 57 [38.4s]: train==[18.49139=18.48142 + 0.00997]
Epoch 58 [38.4s]: train==[18.50591=18.49593 + 0.00998]
Epoch 59 [38.4s + 0.5s]: train==[18.45605=18.44612 + 0.00994], recall=[0.25728, 0.59476], precision=[0.10684, 0.05193], hit=[0.76882, 0.96501], ndcg=[0.21086, 0.31675]
Epoch 60 [38.5s]: train==[18.54242=18.53246 + 0.00997]
Epoch 61 [39.0s]: train==[18.67488=18.66516 + 0.00972]
Epoch 62 [39.7s]: train==[18.51595=18.50620 + 0.00975]
Epoch 63 [38.9s]: train==[18.26924=18.25932 + 0.00992]
Epoch 64 [38.9s]: train==[18.57251=18.56270 + 0.00980]
Epoch 65 [38.8s]: train==[18.20952=18.19961 + 0.00992]
Epoch 66 [39.4s]: train==[18.62872=18.61906 + 0.00967]
Epoch 67 [38.8s]: train==[17.86468=17.85474 + 0.00995]
Epoch 68 [39.2s]: train==[18.39875=18.38874 + 0.01001]
Epoch 69 [38.8s + 0.5s]: train==[18.28991=18.28009 + 0.00982], recall=[0.26475, 0.59854], precision=[0.10832, 0.05217], hit=[0.79109, 0.96076], ndcg=[0.21532, 0.32002]
save the weights in path:  models/ml100k/07_lstm2/69.pkl
Epoch 70 [38.7s]: train==[18.17838=18.16839 + 0.00998]
Epoch 71 [38.8s]: train==[18.28271=18.27282 + 0.00989]
Epoch 72 [39.1s]: train==[18.03143=18.02152 + 0.00991]
Epoch 73 [38.9s]: train==[18.27102=18.26122 + 0.00981]
Epoch 74 [38.5s]: train==[18.13368=18.12375 + 0.00994]
Epoch 75 [38.4s]: train==[18.10480=18.09482 + 0.00998]
Epoch 76 [38.4s]: train==[18.30512=18.29521 + 0.00991]
Epoch 77 [38.4s]: train==[18.12790=18.11794 + 0.00995]
Epoch 78 [38.4s]: train==[18.23918=18.22915 + 0.01003]
Epoch 79 [38.4s + 0.5s]: train==[18.14330=18.13338 + 0.00992], recall=[0.26100, 0.60194], precision=[0.10832, 0.05269], hit=[0.77200, 0.96394], ndcg=[0.21616, 0.32317]
Epoch 80 [38.5s]: train==[17.96498=17.95496 + 0.01002]
Epoch 81 [38.5s]: train==[17.90573=17.89567 + 0.01006]
Epoch 82 [38.6s]: train==[18.32761=18.31748 + 0.01012]
Epoch 83 [38.4s]: train==[17.84685=17.83673 + 0.01011]
Epoch 84 [38.4s]: train==[17.93791=17.92781 + 0.01010]
Epoch 85 [38.4s]: train==[18.17211=18.16195 + 0.01015]
Epoch 86 [38.4s]: train==[17.92685=17.91640 + 0.01045]
Epoch 87 [38.4s]: train==[18.05207=18.04177 + 0.01030]
Epoch 88 [38.4s]: train==[17.97084=17.96035 + 0.01049]
Epoch 89 [38.4s + 0.5s]: train==[17.75049=17.73986 + 0.01063], recall=[0.25772, 0.59310], precision=[0.10705, 0.05157], hit=[0.77200, 0.96607], ndcg=[0.21570, 0.32045]
Epoch 90 [38.8s]: train==[17.86030=17.84958 + 0.01072]
Epoch 91 [38.6s]: train==[18.03766=18.02710 + 0.01056]
Epoch 92 [38.6s]: train==[18.09205=18.08113 + 0.01091]
Epoch 93 [38.9s]: train==[18.05033=18.03969 + 0.01064]
Epoch 94 [38.8s]: train==[17.78569=17.77465 + 0.01105]
Epoch 95 [39.0s]: train==[17.96183=17.95076 + 0.01108]
Epoch 96 [38.9s]: train==[17.98320=17.97196 + 0.01124]
Epoch 97 [39.2s]: train==[17.74717=17.73591 + 0.01126]
Epoch 98 [39.4s]: train==[17.97769=17.96641 + 0.01127]
Epoch 99 [38.8s + 0.5s]: train==[18.00085=17.98955 + 0.01130], recall=[0.26116, 0.60158], precision=[0.10679, 0.05269], hit=[0.77306, 0.96288], ndcg=[0.21125, 0.31902]
Best Iter=[6]@[3866.2]  recall=[0.26475 0.38158 0.48368 0.54316 0.59854], precision=[0.10832    0.08142 0.06845 0.05872 0.05217], hit=[0.79109  0.88123 0.92365 0.94380 0.96076], ndcg=[0.21532        0.25151 0.28415 0.30339 0.32002]
hephaestos@toto:/media/stock/projets/20220130_CNAM_graphs/NGCF-PyTorch-new/NGCF$ 